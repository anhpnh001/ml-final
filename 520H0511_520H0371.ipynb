{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d403434",
   "metadata": {},
   "source": [
    "\n",
    "## Group Members\n",
    "- 520H0511 - Phan Ngọc Hoàng Anh\n",
    "- 520H0371 - Đặng Nhật Khang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7ee1c",
   "metadata": {},
   "source": [
    "\n",
    "# Pima Indians Diabetes Prediction using Machine Learning and Neural Networks\n",
    "\n",
    "This notebook outlines the process of analyzing the Pima Indians Diabetes Database and applying various machine learning and neural network models to predict diabetes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41f7868",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loading and Initial Analysis\n",
    "\n",
    "First, we load the data and perform initial exploratory analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'path_to_your_data.csv' # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Statistical summary\n",
    "print(data.describe())\n",
    "\n",
    "# Plot histograms\n",
    "data.hist(bins=15, figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='viridis')\n",
    "plt.title(\"Correlation Matrix of Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2dabce",
   "metadata": {},
   "source": [
    "\n",
    "## Machine Learning Models\n",
    "\n",
    "We will now implement basic machine learning models including Logistic Regression, SVM, and Random Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945346cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Splitting the dataset\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# Support Vector Machine\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "y_pred_svc = svc.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80ac3d",
   "metadata": {},
   "source": [
    "\n",
    "## Neural Network Models\n",
    "\n",
    "Below are the implementations for Feed Forward Neural Network (FFNN) and Recurrent Neural Network (RNN). These models should be run in an environment where TensorFlow is installed.\n",
    "\n",
    "### Feed Forward Neural Network (FFNN):\n",
    "This model uses dense layers and dropout for regularization to prevent overfitting. Early stopping is also used to stop training when the validation loss stops improving.\n",
    "\n",
    "### Recurrent Neural Network (RNN):\n",
    "The RNN model uses LSTM (Long Short-Term Memory) layers, suitable for sequence data. This model also includes dropout layers for regularization and early stopping for training efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc388d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Feed Forward Neural Network (FFNN)\n",
    "model_ffnn = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_ffnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "history_ffnn = model_ffnn.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "ffnn_evaluation = model_ffnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "# Recurrent Neural Network (RNN)\n",
    "X_train_scaled_rnn = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_scaled_rnn = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "model_rnn = Sequential([\n",
    "    LSTM(32, input_shape=(1, X_train_scaled.shape[1]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(16),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_rnn = model_rnn.fit(X_train_scaled_rnn, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "rnn_evaluation = model_rnn.evaluate(X_test_scaled_rnn, y_test, verbose=0)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
